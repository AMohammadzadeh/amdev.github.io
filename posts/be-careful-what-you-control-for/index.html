<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Be Careful What You Control For | AMDev</title>
<meta name="keywords" content="Casual Inference">
<meta name="description" content="What is the effect of online learning on students&rsquo; performance? Does attending a top-tier university significantly affect future earnings?
Would a customer still purchase if we hadn’t offered a discount?
We often encounter questions like these in our work or research. They aim to uncover the causal effect of a treatment (e.g., online learning, attending a prestigious university, offering a discount) on a particular outcome (e.g., students&rsquo; performance, future earnings, customer purchases). Intuitively, we recognize that answering such questions is challenging—it requires us to observe the same individual in two different scenarios at the same time. For instance, we’d need to know whether the same customer would have purchased if they had not received the discount. This concept is referred to as potential outcomes.">
<meta name="author" content="Ahmad M.">
<link rel="canonical" href="https://amohammadzadeh.github.io/posts/be-careful-what-you-control-for/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://amohammadzadeh.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://amohammadzadeh.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://amohammadzadeh.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://amohammadzadeh.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://amohammadzadeh.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://amohammadzadeh.github.io/posts/be-careful-what-you-control-for/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript> <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
  crossorigin="anonymous"
/>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
  crossorigin="anonymous"
></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
  crossorigin="anonymous"
  onload="renderMathInElement(document.body);"
></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\[", right: "\]", display: false },
      ],
    });
  });
</script>
 

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-T3FF73RDK5"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-T3FF73RDK5');
        }
      </script><meta property="og:url" content="https://amohammadzadeh.github.io/posts/be-careful-what-you-control-for/">
  <meta property="og:site_name" content="AMDev">
  <meta property="og:title" content="Be Careful What You Control For">
  <meta property="og:description" content="What is the effect of online learning on students’ performance? Does attending a top-tier university significantly affect future earnings? Would a customer still purchase if we hadn’t offered a discount?
We often encounter questions like these in our work or research. They aim to uncover the causal effect of a treatment (e.g., online learning, attending a prestigious university, offering a discount) on a particular outcome (e.g., students’ performance, future earnings, customer purchases). Intuitively, we recognize that answering such questions is challenging—it requires us to observe the same individual in two different scenarios at the same time. For instance, we’d need to know whether the same customer would have purchased if they had not received the discount. This concept is referred to as potential outcomes.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-11-19T21:52:37+03:30">
    <meta property="article:modified_time" content="2024-11-19T21:52:37+03:30">
    <meta property="article:tag" content="Casual Inference">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Be Careful What You Control For">
<meta name="twitter:description" content="What is the effect of online learning on students&rsquo; performance? Does attending a top-tier university significantly affect future earnings?
Would a customer still purchase if we hadn’t offered a discount?
We often encounter questions like these in our work or research. They aim to uncover the causal effect of a treatment (e.g., online learning, attending a prestigious university, offering a discount) on a particular outcome (e.g., students&rsquo; performance, future earnings, customer purchases). Intuitively, we recognize that answering such questions is challenging—it requires us to observe the same individual in two different scenarios at the same time. For instance, we’d need to know whether the same customer would have purchased if they had not received the discount. This concept is referred to as potential outcomes.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://amohammadzadeh.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Be Careful What You Control For",
      "item": "https://amohammadzadeh.github.io/posts/be-careful-what-you-control-for/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Be Careful What You Control For",
  "name": "Be Careful What You Control For",
  "description": "What is the effect of online learning on students\u0026rsquo; performance? Does attending a top-tier university significantly affect future earnings? Would a customer still purchase if we hadn’t offered a discount?\nWe often encounter questions like these in our work or research. They aim to uncover the causal effect of a treatment (e.g., online learning, attending a prestigious university, offering a discount) on a particular outcome (e.g., students\u0026rsquo; performance, future earnings, customer purchases). Intuitively, we recognize that answering such questions is challenging—it requires us to observe the same individual in two different scenarios at the same time. For instance, we’d need to know whether the same customer would have purchased if they had not received the discount. This concept is referred to as potential outcomes.\n",
  "keywords": [
    "Casual Inference"
  ],
  "articleBody": "What is the effect of online learning on students’ performance? Does attending a top-tier university significantly affect future earnings? Would a customer still purchase if we hadn’t offered a discount?\nWe often encounter questions like these in our work or research. They aim to uncover the causal effect of a treatment (e.g., online learning, attending a prestigious university, offering a discount) on a particular outcome (e.g., students’ performance, future earnings, customer purchases). Intuitively, we recognize that answering such questions is challenging—it requires us to observe the same individual in two different scenarios at the same time. For instance, we’d need to know whether the same customer would have purchased if they had not received the discount. This concept is referred to as potential outcomes.\n$Y_0$: The outcome an individual would experience without the treatment. $Y_1$: The outcome the same individual would experience under the treatment. Now, let’s assume we can randomly assign discounts to customers. In such a scenario, the following regression equation suffices:\n$$Purchase_i = \\beta_0 + \\beta_1 Discount_i + u_i$$\nIt can be shown that the estimate of $\\beta_1$ ($\\hat{\\beta}_1$) represents the effect of the discount on purchases.\nSounds straightforward, right? Unfortunately, conducting randomized controlled trials (RCTs) isn’t always feasible. This brings us to our next challenge: how can we extract causal insights from observational data? Specifically, what controls should we include in the regression? Can’t we just include every available variable and let the model do its magic? (Spoiler: if that worked, there would be no need for this article!)\nIdentifying Proper Controls First, let’s discuss the variables we must include in our model. In our earlier example, assume the advertising budget influences both discounts and purchases. Retailers may pair discounts with large advertising campaigns, and advertising itself can increase purchases by raising awareness. Here, the advertising budget acts as a confounder. If we omit this confounder from our regression, the estimated impact of discounts ($\\hat{\\beta}_1$) will also capture the effect of advertising.\nimport numpy as np import pandas as pd import matplotlib.pyplot as plt import statsmodels.api as sm np.random.seed(42) n = 500 confounder = np.random.normal(0, 1, n) # Advertising budget X = 2 * confounder + np.random.normal(0, 1, n) # Discount Y = 3 * X + 4 * confounder + np.random.normal(0, 1, n) # Purchase data = pd.DataFrame({'X': X, 'Z': confounder, 'Y': Y}) X_only = sm.add_constant(data['X']) model_omitted = sm.OLS(data['Y'], X_only).fit() XZ = sm.add_constant(data[['X', 'Z']]) model_controlled = sm.OLS(data['Y'], XZ).fit() print(\"Regression without controlling for Z (omitted variable bias):\") print(model_omitted.summary()) print(\"Regression controlling for Z (true model):\") print(model_controlled.summary()) Regression without controlling for confounder (omitted variable bias): ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const 0.0616 0.089 0.693 0.488 -0.113 0.236 X 4.6321 0.042 110.762 0.000 4.550 4.714 ============================================================================== Regression controlling for confounder (true model): ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const 0.1065 0.045 2.361 0.019 0.018 0.195 X 3.0745 0.046 66.445 0.000 2.984 3.165 Z 3.7972 0.100 37.887 0.000 3.600 3.994 ============================================================================== By excluding the confounder, we overestimate the effect of discounts on purchases.\nAvoiding Bad Controls Now that we understand the importance of including confounders, let’s discuss bad controls—variables that should not be included in the model.\n1. Mediators Imagine we aim to measure the effect of education ($X$) on income ($Y$), but we include skills as a control variable. Since skills are developed through education and directly affect income, they act as a mediator because they lie on the causal path between the treatment and the outcome. Controlling for skills would block part of education’s effect on income, leading to a biased estimate of the total effect.\nnp.random.seed(42) n = 500 education = np.random.normal(12, 2, n) skills = 1.5 * education + np.random.normal(0, 1, n) income = 2 * education + 4 * skills + np.random.normal(0, 2, n) data = pd.DataFrame({'Education': education, 'Skills': skills, 'Income': income}) X1 = sm.add_constant(data['Education']) model1 = sm.OLS(data['Income'], X1).fit() X2 = sm.add_constant(data[['Education', 'Skills']]) model2 = sm.OLS(data['Income'], X2).fit() print(\"Without controlling for skills:\\n\", model1.summary()) print(\"Controlling for skills:\\n\", model2.summary()) Without controlling for skills: ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const 2.8712 1.256 2.286 0.023 0.404 5.339 Education 7.7897 0.103 75.499 0.000 7.587 7.992 ============================================================================== Controlling for skills: ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const 0.8596 0.562 1.531 0.126 -0.244 1.963 Education 1.7228 0.143 12.054 0.000 1.442 2.004 Skills 4.1489 0.093 44.833 0.000 3.967 4.331 ============================================================================== In practical terms, when we control for skills, we inadvertently narrow our focus to only the variation in education that does not impact skills—ignoring a crucial mechanism through which education influences income. As a result, the regression estimates reflect only the direct effect of education on income, not the complete picture.\nA similar problem arises if we control for variables that are descendants of mediators—those influenced by mediators. For instance, let’s say education enhances skills (a mediator), which in turn leads to better job performance evaluations. Controlling for job performance would bias our estimate of education’s total effect on income because we would once again be blocking part of the causal path.\nKeep in mind that while controlling for skills (a mediator) biases the estimate of the total effect of education on income, it allows us to estimate the direct effect of education that is not transmitted through skills. Depending on the research question, estimating the direct effect might be of interest.\nnp.random.seed(42) n = 500 education = np.random.normal(12, 2, n) skills = 1.5 * education + np.random.normal(0, 1, n) performance = 2 * skills + np.random.normal(0, 1, n) income = 2 * education + 4 * skills + np.random.normal(0, 2, n) data = pd.DataFrame({'Education': education, 'Skills': skills, 'Income': income, 'Performance':performance}) X1 = sm.add_constant(data['Education']) model1 = sm.OLS(data['Income'], X1).fit() X2 = sm.add_constant(data[['Education', 'Performance']]) model2 = sm.OLS(data['Income'], X2).fit() print(\"Without controlling for performance:\\n\", model1.summary()) print(\"Controlling for performance:\\n\", model2.summary()) Without controlling for performance: ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const 1.2331 1.206 1.023 0.307 -1.136 3.602 Education 7.9135 0.099 79.897 0.000 7.719 8.108 ============================================================================== Controlling for performance: =============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------- const -0.9580 0.736 -1.301 0.194 -2.404 0.488 Education 3.4954 0.163 21.473 0.000 3.176 3.815 Performance 1.5262 0.052 29.208 0.000 1.424 1.629 ============================================================================== 2. Colliders Colliders are variables influenced by both the treatment and the outcome. For example, consider a scenario where both education and income impact networking opportunities. Let’s see what happens when we control for this:\nnp.random.seed(42) n = 500 education = np.random.normal(12, 2, n) income = 2 * education + np.random.normal(0, 2, n) networking = 1.5 * education + 2 * income + np.random.normal(0, 1, n) data = pd.DataFrame({'Education': education, 'Income': income, 'Networking':networking}) X1 = sm.add_constant(data['Education']) model1 = sm.OLS(data['Income'], X1).fit() X2 = sm.add_constant(data[['Education', 'Networking']]) model2 = sm.OLS(data['Income'], X2).fit() print(\"Without controlling for networking:\\n\", model1.summary()) print(\"Controlling for networking:\\n\", model2.summary()) Without controlling for networking: ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const 0.9697 0.542 1.789 0.074 -0.095 2.035 Education 1.9246 0.045 43.216 0.000 1.837 2.012 ============================================================================== Controlling for networking: ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const -0.1398 0.134 -1.045 0.296 -0.403 0.123 Education -0.5292 0.030 -17.679 0.000 -0.588 -0.470 Networking 0.4613 0.005 88.057 0.000 0.451 0.472 ============================================================================== Controlling for networking, we see that education has a negative effect on income. When we control for networking, we’re looking at the relationship between education and income as if everyone had the same level of networking. Since both income and education affects networking, it is possible that a person with high education and low income, or low education and high income has a good level of networking. In other words, we’re essentially comparing people who have achieved similar networking status but possibly through different paths.\nThe same logic applies to variables that are descendants of colliders. Controlling for such variables introduces a spurious association between the treatment and outcome, leading to misleading conclusions.\n3. M-Structure Bias The M-structure is a slightly more complex form of bias that occurs when a variable is influenced by two unobserved factors that also independently affect the treatment and the outcome. For example:\n$U_1$ represents intrinsic motivation, influencing both education (treatment) and participation in extracurricular activities ($W$). $U_2$ represents social networks, influencing both income (outcome) and extracurricular activities ($W$). Extracurricular activities ($W$) thus act as a collider affected by $U_1$ and $U_2$.\nThese variables and causal paths form a structure which looks like the letter ‘M’ (hence the name). This is shown in Figure 1. Figure 1: M-Structure (adapted from Ding, P., \u0026 Miratrix, L. W. (2015))\nLet’s see what will happen if we control for W:\nnp.random.seed(42) n = 500 u1 = np.random.normal(0, 1, n) u2 = np.random.normal(0, 1, n) education = 1.5 * u1 + np.random.normal(12, 2, n) income = 2 * education + 3 * u2 + np.random.normal(0, 2, n) w = 1.5 * u1 + 2.5 * u2 + np.random.normal(0, 1, n) data = pd.DataFrame({ 'Education': education, 'Income': income, 'W': w }) X1 = sm.add_constant(data['Education']) model1 = sm.OLS(data['Income'], X1).fit() X2 = sm.add_constant(data[['Education', 'W']]) model2 = sm.OLS(data['Income'], X2).fit() print(\"Without controlling for W (total effect):\\n\", model1.summary()) print(\"Controlling for W (biased estimate):\\n\", model2.summary()) Without controlling for W (total effect): ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const -0.2980 0.804 -0.371 0.711 -1.877 1.281 Education 2.0376 0.064 31.604 0.000 1.911 2.164 ============================================================================== Controlling for W (biased estimate): ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const 3.1650 0.608 5.206 0.000 1.971 4.359 Education 1.7489 0.049 35.758 0.000 1.653 1.845 W 0.8515 0.040 21.032 0.000 0.772 0.931 ============================================================================== The result shows that $W$ has a significant coefficient in the second regression due to the spurious association introduced by conditioning on it, despite $W$ not being part of the direct causal pathway between education and income. Why is that? As we’ve discussed before, conditioning on W means we decide to focus only on people who participate in extracurricular activities ($W$) at a similar level. What happens here is that different combinations of $U_1$ and $U_2$ lead to the same $W$. For instance, Person A might have a high $U_1$ (high intrinsic motivation) but a low $U_2$ (weak social network), leading to moderate participation in extracurriculars ($W$). Person B might have a low $U_1$ but a high $U_2$, resulting in the same level of $W$. Person A’s high $U_1$ leads to higher education ($T$), while Person B’s high $U_2$ leads to higher income ($Y$). When we condition on $W$, these two effects seem related: people with higher education also appear to have higher income; but this relationship is spurious and introduced by conditioning on $W$.\n4. Bias Amplification Let’s consider a scenario where we already have an omitted variable bias (OVB) due to an unmeasured factor, such as innate ability ($U_1$), which affects both education and income. There is also access to resource (X) like good schools, which only affects education.\nnp.random.seed(42) n = 500 u1 = np.random.normal(0, 1, n) x = np.random.normal(0, 1, n) education = 1.5 * u1 + 4 * x + np.random.normal(12, 2, n) income = 2 * education + 3 * u1+ np.random.normal(0, 2, n) data = pd.DataFrame({ 'Education': education, 'Income': income, 'X': x }) X1 = sm.add_constant(data['Education']) model1 = sm.OLS(data['Income'], X1).fit() X2 = sm.add_constant(data[['Education', 'X']]) model2 = sm.OLS(data['Income'], X2).fit() print(\"Without controlling for X (biased due to omitted variable u_1):\\n\", model1.summary()) print(\"Controlling for X (bias amplified due to conditioning on X):\\n\", model2.summary()) Without controlling for X (biased due to omitted variable u_1): ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const -1.6623 0.457 -3.640 0.000 -2.560 -0.765 Education 2.1416 0.035 61.873 0.000 2.074 2.210 ============================================================================== Controlling for X (bias amplified due to conditioning on X): ============================================================================== coef std err t P\u003e|t| [0.025 0.975] ------------------------------------------------------------------------------ const -8.3924 0.741 -11.327 0.000 -9.848 -6.937 Education 2.6943 0.059 45.326 0.000 2.577 2.811 X -3.0782 0.282 -10.913 0.000 -3.632 -2.524 ============================================================================== It seems that controlling for X exacerbates our existing bias. This is because by focusing on people with the same X, any difference in education between these individuals must now come from their innate ability ($U_1$). That is, if two people had the same access to resources, the one with higher education likely had a higher innate ability. As a result, since X is no longer contributing to the differences in education, innate ability explains a larger share of the variation in education. Remember, $U_1$ also directly affects income. So, when education appears higher for someone due to their innate ability, part of their higher income is due to the same innate ability. This means some of the effect of innate ability on income get wrongly attributed to education.\nConclusion In this article, we explored various sources of bias that can arise when deciding which variables to include in a regression model. These include:\nMediator bias: Blocking part of the causal path by controlling for variables that mediate the effect of the treatment on the outcome. Collider bias: Introducing spurious associations by controlling for variables influenced by both the treatment and the outcome. M-bias: Creating artificial relationships between unobserved variables by conditioning on colliders. Bias amplification: Exacerbating existing biases by conditioning on a variable that has no effect on the outcome except for an indirect effect via treatment. The key takeaway is that we should carefully consider the causal relationships among variables before deciding whether to adjust for a particular variable.\nReferences Cinelli, C., Forney, A., \u0026 Pearl, J. (2022). A Crash Course in Good and Bad Controls. Sociological Methods \u0026 Research, 0 (0), 1-34. Ding, P., \u0026 Miratrix, L. W. (2015). To adjust or not to adjust? Sensitivity analysis of M-bias and butterfly-bias. Journal of Causal Inference, 3(1), 41-57. Facure, M. (2023). Causal Inference in Python. \" O’Reilly Media, Inc.\". ",
  "wordCount" : "2254",
  "inLanguage": "en",
  "datePublished": "2024-11-19T21:52:37+03:30",
  "dateModified": "2024-11-19T21:52:37+03:30",
  "author":{
    "@type": "Person",
    "name": "Ahmad M."
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://amohammadzadeh.github.io/posts/be-careful-what-you-control-for/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "AMDev",
    "logo": {
      "@type": "ImageObject",
      "url": "https://amohammadzadeh.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://amohammadzadeh.github.io/" accesskey="h" title="AMDev (Alt + H)">AMDev</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://amohammadzadeh.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://amohammadzadeh.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Be Careful What You Control For
    </h1>
    <div class="post-meta"><span title='2024-11-19 21:52:37 +0330 +0330'>November 19, 2024</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;Ahmad M.

</div>
  </header> 
  <div class="post-content"><p>What is the effect of online learning on students&rsquo; performance? Does attending a top-tier university significantly affect future earnings?
Would a customer still purchase if we hadn’t offered a discount?</p>
<p>We often encounter questions like these in our work or research. They aim to uncover the causal effect of a treatment (e.g., online learning, attending a prestigious university, offering a discount) on a particular outcome (e.g., students&rsquo; performance, future earnings, customer purchases). Intuitively, we recognize that answering such questions is challenging—it requires us to observe the same individual in two different scenarios at the same time. For instance, we’d need to know whether the same customer would have purchased if they had not received the discount. This concept is referred to as <strong>potential outcomes</strong>.</p>
<ul>
<li>$Y_0$: The outcome an individual would experience without the treatment.</li>
<li>$Y_1$: The outcome the same individual would experience under the treatment.</li>
</ul>
<p>Now, let’s assume we can randomly assign discounts to customers. In such a scenario, the following regression equation suffices:</p>
<p>$$Purchase_i = \beta_0 + \beta_1 Discount_i + u_i$$</p>
<p>It can be shown that the estimate of $\beta_1$ ($\hat{\beta}_1$) represents the effect of the discount on purchases.</p>
<p>Sounds straightforward, right? Unfortunately, conducting randomized controlled trials (RCTs) isn&rsquo;t always feasible. This brings us to our next challenge: how can we extract causal insights from <strong>observational data</strong>? Specifically, what controls should we include in the regression? Can’t we just include every available variable and let the model do its magic? (Spoiler: if that worked, there would be no need for this article!)</p>
<h3 id="identifying-proper-controls">Identifying Proper Controls<a hidden class="anchor" aria-hidden="true" href="#identifying-proper-controls">#</a></h3>
<p>First, let’s discuss the variables we must include in our model. In our earlier example, assume the <strong>advertising budget</strong> influences both discounts and purchases. Retailers may pair discounts with large advertising campaigns, and advertising itself can increase purchases by raising awareness. Here, the advertising budget acts as a <strong>confounder</strong>. If we omit this confounder from our regression, the estimated impact of discounts ($\hat{\beta}_1$) will also capture the effect of advertising.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> statsmodels.api <span style="color:#66d9ef">as</span> sm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>confounder <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n) <span style="color:#75715e"># Advertising budget</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> confounder <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n) <span style="color:#75715e"># Discount</span>
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> X <span style="color:#f92672">+</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> confounder <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n) <span style="color:#75715e"># Purchase</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;X&#39;</span>: X, <span style="color:#e6db74">&#39;Z&#39;</span>: confounder, <span style="color:#e6db74">&#39;Y&#39;</span>: Y})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_only <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[<span style="color:#e6db74">&#39;X&#39;</span>])
</span></span><span style="display:flex;"><span>model_omitted <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Y&#39;</span>], X_only)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>XZ <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[[<span style="color:#e6db74">&#39;X&#39;</span>, <span style="color:#e6db74">&#39;Z&#39;</span>]])
</span></span><span style="display:flex;"><span>model_controlled <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Y&#39;</span>], XZ)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Regression without controlling for Z (omitted variable bias):&#34;</span>)
</span></span><span style="display:flex;"><span>print(model_omitted<span style="color:#f92672">.</span>summary())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Regression controlling for Z (true model):&#34;</span>)
</span></span><span style="display:flex;"><span>print(model_controlled<span style="color:#f92672">.</span>summary())
</span></span></code></pre></div><pre tabindex="0"><code>Regression without controlling for confounder (omitted variable bias):
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.0616      0.089      0.693      0.488      -0.113       0.236
X              4.6321      0.042    110.762      0.000       4.550       4.714
==============================================================================
</code></pre><pre tabindex="0"><code>Regression controlling for confounder (true model):
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.1065      0.045      2.361      0.019       0.018       0.195
X              3.0745      0.046     66.445      0.000       2.984       3.165
Z              3.7972      0.100     37.887      0.000       3.600       3.994
==============================================================================
</code></pre><p>By excluding the confounder, we overestimate the effect of discounts on purchases.</p>
<hr>
<h3 id="avoiding-bad-controls">Avoiding Bad Controls<a hidden class="anchor" aria-hidden="true" href="#avoiding-bad-controls">#</a></h3>
<p>Now that we understand the importance of including confounders, let’s discuss <strong>bad controls</strong>—variables that should <strong>not</strong> be included in the model.</p>
<h4 id="1-mediators">1. Mediators<a hidden class="anchor" aria-hidden="true" href="#1-mediators">#</a></h4>
<p>Imagine we aim to measure the effect of education ($X$) on income ($Y$), but we include skills as a control variable. Since skills are developed through education and directly affect income, they act as a <strong>mediator</strong> because they lie on the causal path between the treatment and the outcome. Controlling for skills would block part of education’s effect on income, leading to a biased estimate of the <strong>total effect</strong>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>education <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>skills <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>income <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> skills <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;Education&#39;</span>: education, <span style="color:#e6db74">&#39;Skills&#39;</span>: skills, <span style="color:#e6db74">&#39;Income&#39;</span>: income})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[<span style="color:#e6db74">&#39;Education&#39;</span>])
</span></span><span style="display:flex;"><span>model1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X1)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[[<span style="color:#e6db74">&#39;Education&#39;</span>, <span style="color:#e6db74">&#39;Skills&#39;</span>]])
</span></span><span style="display:flex;"><span>model2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X2)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Without controlling for skills:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model1<span style="color:#f92672">.</span>summary())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Controlling for skills:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model2<span style="color:#f92672">.</span>summary())
</span></span></code></pre></div><pre tabindex="0"><code>Without controlling for skills:
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          2.8712      1.256      2.286      0.023       0.404       5.339
Education      7.7897      0.103     75.499      0.000       7.587       7.992
==============================================================================
</code></pre><pre tabindex="0"><code>Controlling for skills:
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.8596      0.562      1.531      0.126      -0.244       1.963
Education      1.7228      0.143     12.054      0.000       1.442       2.004
Skills         4.1489      0.093     44.833      0.000       3.967       4.331
==============================================================================
</code></pre><p>In practical terms, when we control for skills, we inadvertently narrow our focus to only the variation in education that does not impact skills—ignoring a crucial mechanism through which education influences income. As a result, the regression estimates reflect only the direct effect of education on income, not the complete picture.</p>
<p>A similar problem arises if we control for variables that are <strong>descendants of mediators</strong>—those influenced by mediators. For instance, let’s say education enhances skills (a mediator), which in turn leads to better job performance evaluations. Controlling for job performance would bias our estimate of education’s total effect on income because we would once again be blocking part of the causal path.</p>
<p>Keep in mind that while controlling for skills (a mediator) biases the estimate of the total effect of education on income, it allows us to estimate the direct effect of education that is not transmitted through skills. Depending on the research question, estimating the direct effect might be of interest.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>education <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>skills <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>performance <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> skills <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>income <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> skills <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;Education&#39;</span>: education, <span style="color:#e6db74">&#39;Skills&#39;</span>: skills, <span style="color:#e6db74">&#39;Income&#39;</span>: income, <span style="color:#e6db74">&#39;Performance&#39;</span>:performance})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[<span style="color:#e6db74">&#39;Education&#39;</span>])
</span></span><span style="display:flex;"><span>model1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X1)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[[<span style="color:#e6db74">&#39;Education&#39;</span>, <span style="color:#e6db74">&#39;Performance&#39;</span>]])
</span></span><span style="display:flex;"><span>model2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X2)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Without controlling for performance:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model1<span style="color:#f92672">.</span>summary())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Controlling for performance:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model2<span style="color:#f92672">.</span>summary())
</span></span></code></pre></div><pre tabindex="0"><code>Without controlling for performance:
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          1.2331      1.206      1.023      0.307      -1.136       3.602
Education      7.9135      0.099     79.897      0.000       7.719       8.108
==============================================================================
</code></pre><pre tabindex="0"><code>Controlling for performance:
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
const          -0.9580      0.736     -1.301      0.194      -2.404       0.488
Education       3.4954      0.163     21.473      0.000       3.176       3.815
Performance     1.5262      0.052     29.208      0.000       1.424       1.629
==============================================================================
</code></pre><hr>
<h4 id="2-colliders">2. Colliders<a hidden class="anchor" aria-hidden="true" href="#2-colliders">#</a></h4>
<p>Colliders are variables influenced by both the treatment and the outcome. For example, consider a scenario where both education and income impact <strong>networking opportunities</strong>. Let&rsquo;s see what happens when we control for this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>education <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>income <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>networking <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> income <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;Education&#39;</span>: education, <span style="color:#e6db74">&#39;Income&#39;</span>: income, <span style="color:#e6db74">&#39;Networking&#39;</span>:networking})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[<span style="color:#e6db74">&#39;Education&#39;</span>])
</span></span><span style="display:flex;"><span>model1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X1)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[[<span style="color:#e6db74">&#39;Education&#39;</span>, <span style="color:#e6db74">&#39;Networking&#39;</span>]])
</span></span><span style="display:flex;"><span>model2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X2)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Without controlling for networking:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model1<span style="color:#f92672">.</span>summary())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Controlling for networking:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model2<span style="color:#f92672">.</span>summary())
</span></span></code></pre></div><pre tabindex="0"><code>Without controlling for networking:
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.9697      0.542      1.789      0.074      -0.095       2.035
Education      1.9246      0.045     43.216      0.000       1.837       2.012
==============================================================================
</code></pre><pre tabindex="0"><code>Controlling for networking:
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.1398      0.134     -1.045      0.296      -0.403       0.123
Education     -0.5292      0.030    -17.679      0.000      -0.588      -0.470
Networking     0.4613      0.005     88.057      0.000       0.451       0.472
==============================================================================
</code></pre><p>Controlling for networking, we see that education has a negative effect on income. When we control for networking, we&rsquo;re looking at the relationship between education and income as if everyone had the same level of networking. Since both income and education affects networking, it is possible that a person with <strong>high education</strong> and <strong>low income</strong>, or <strong>low education</strong> and <strong>high income</strong> has a good level of networking. In other words, we&rsquo;re essentially comparing people who have achieved similar networking status but possibly through different paths.</p>
<p>The same logic applies to variables that are descendants of colliders. Controlling for such variables introduces a spurious association between the treatment and outcome, leading to misleading conclusions.</p>
<hr>
<h4 id="3-m-structure-bias">3. M-Structure Bias<a hidden class="anchor" aria-hidden="true" href="#3-m-structure-bias">#</a></h4>
<p>The <strong>M-structure</strong> is a slightly more complex form of bias that occurs when a variable is influenced by two unobserved factors that also independently affect the treatment and the outcome. For example:</p>
<ul>
<li>$U_1$ represents intrinsic motivation, influencing both education (treatment) and participation in extracurricular activities ($W$).</li>
<li>$U_2$ represents social networks, influencing both income (outcome) and extracurricular activities ($W$).</li>
</ul>
<p>Extracurricular activities ($W$) thus act as a <strong>collider</strong> affected by $U_1$ and $U_2$.</p>
<p>These variables and causal paths form a structure which looks like the letter &lsquo;M&rsquo; (hence the name). This is shown in <a href="#figure-1">Figure 1</a>.
<figure id="figure-1" class="align-center "><img loading="lazy" src="/mstructure.png#center" alt="mstructure" width="200"/><figcaption><p>
          Figure 1: M-Structure (adapted from Ding, P., &amp; Miratrix, L. W. (2015))</p></figcaption></figure>
</p>
<p>Let&rsquo;s see what will happen if we control for W:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>u1 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>u2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>education <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> u1 <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>income <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> u2 <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>w <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> u1 <span style="color:#f92672">+</span> <span style="color:#ae81ff">2.5</span> <span style="color:#f92672">*</span> u2 <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Education&#39;</span>: education,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Income&#39;</span>: income,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;W&#39;</span>: w
</span></span><span style="display:flex;"><span>})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[<span style="color:#e6db74">&#39;Education&#39;</span>])
</span></span><span style="display:flex;"><span>model1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X1)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[[<span style="color:#e6db74">&#39;Education&#39;</span>, <span style="color:#e6db74">&#39;W&#39;</span>]])
</span></span><span style="display:flex;"><span>model2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X2)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Without controlling for W (total effect):</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model1<span style="color:#f92672">.</span>summary())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Controlling for W (biased estimate):</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model2<span style="color:#f92672">.</span>summary())
</span></span></code></pre></div><pre tabindex="0"><code>Without controlling for W (total effect):
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.2980      0.804     -0.371      0.711      -1.877       1.281
Education      2.0376      0.064     31.604      0.000       1.911       2.164
==============================================================================
</code></pre><pre tabindex="0"><code>Controlling for W (biased estimate):
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.1650      0.608      5.206      0.000       1.971       4.359
Education      1.7489      0.049     35.758      0.000       1.653       1.845
W              0.8515      0.040     21.032      0.000       0.772       0.931
==============================================================================
</code></pre><p>The result shows that $W$ has a significant coefficient in the second regression due to the spurious association introduced by conditioning on it, despite $W$ not being part of the direct causal pathway between education and income. Why is that? As we&rsquo;ve discussed before, conditioning on W means we decide to focus only on people who participate in extracurricular activities ($W$) at a similar level. What happens here is that different combinations of $U_1$ and $U_2$ lead to the same $W$. For instance, Person A might have a high $U_1$ (high intrinsic motivation) but a low $U_2$ (weak social network), leading to moderate participation in extracurriculars ($W$). Person B might have a low $U_1$ but a high $U_2$, resulting in the same level of $W$. Person A&rsquo;s high $U_1$ leads to higher education ($T$), while Person B&rsquo;s high $U_2$ leads to higher income ($Y$). When we condition on $W$, these two effects seem related: people with higher education also appear to have higher income; but this relationship is spurious and introduced by conditioning on $W$.</p>
<hr>
<h4 id="4-bias-amplification">4. Bias Amplification<a hidden class="anchor" aria-hidden="true" href="#4-bias-amplification">#</a></h4>
<p>Let’s consider a scenario where we already have an <strong>omitted variable bias (OVB)</strong> due to an unmeasured factor, such as innate ability ($U_1$), which affects both education and income. There is also access to resource (X) like good schools, which only affects education.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>u1 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, n)
</span></span><span style="display:flex;"><span>education <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> u1 <span style="color:#f92672">+</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> x <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>income <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> education <span style="color:#f92672">+</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> u1<span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, n)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Education&#39;</span>: education,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Income&#39;</span>: income,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;X&#39;</span>: x
</span></span><span style="display:flex;"><span>})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[<span style="color:#e6db74">&#39;Education&#39;</span>])
</span></span><span style="display:flex;"><span>model1 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X1)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>add_constant(data[[<span style="color:#e6db74">&#39;Education&#39;</span>, <span style="color:#e6db74">&#39;X&#39;</span>]])
</span></span><span style="display:flex;"><span>model2 <span style="color:#f92672">=</span> sm<span style="color:#f92672">.</span>OLS(data[<span style="color:#e6db74">&#39;Income&#39;</span>], X2)<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Without controlling for X (biased due to omitted variable u_1):</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model1<span style="color:#f92672">.</span>summary())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Controlling for X (bias amplified due to conditioning on X):</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, model2<span style="color:#f92672">.</span>summary())
</span></span></code></pre></div><pre tabindex="0"><code>Without controlling for X (biased due to omitted variable u_1):
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -1.6623      0.457     -3.640      0.000      -2.560      -0.765
Education      2.1416      0.035     61.873      0.000       2.074       2.210
==============================================================================
</code></pre><pre tabindex="0"><code>Controlling for X (bias amplified due to conditioning on X):
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -8.3924      0.741    -11.327      0.000      -9.848      -6.937
Education      2.6943      0.059     45.326      0.000       2.577       2.811
X             -3.0782      0.282    -10.913      0.000      -3.632      -2.524
==============================================================================
</code></pre><p>It seems that controlling for X exacerbates our existing bias. This is because by focusing on people with the same X, any difference in education between these individuals must now come from their innate ability ($U_1$). That is, if two people had the same access to resources, the one with higher education likely had a higher innate ability. As a result, since X is no longer contributing to the differences in education, innate ability explains a larger share of the variation in education. Remember, $U_1$ also directly affects income. So, when education appears higher for someone due to their innate ability, part of their higher income is due to the same innate ability. This means some of the effect of innate ability on income get wrongly attributed to education.</p>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>In this article, we explored various sources of bias that can arise when deciding which variables to include in a regression model. These include:</p>
<ul>
<li><strong>Mediator bias</strong>: Blocking part of the causal path by controlling for variables that mediate the effect of the treatment on the outcome.</li>
<li><strong>Collider bias</strong>: Introducing spurious associations by controlling for variables influenced by both the treatment and the outcome.</li>
<li><strong>M-bias</strong>: Creating artificial relationships between unobserved variables by conditioning on colliders.</li>
<li><strong>Bias amplification</strong>: Exacerbating existing biases by conditioning on a variable that has no effect on the outcome except for an indirect effect via treatment.</li>
</ul>
<p>The key takeaway is that we should carefully consider the causal relationships among variables before deciding whether to adjust for a particular variable.</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<ol>
<li>Cinelli, C., Forney, A., &amp; Pearl, J. (2022). <em>A Crash Course in Good and Bad Controls. Sociological
Methods &amp; Research</em>, 0 (0), 1-34.</li>
<li>Ding, P., &amp; Miratrix, L. W. (2015). <em>To adjust or not to adjust? Sensitivity analysis of M-bias and butterfly-bias. Journal of Causal Inference</em>, 3(1), 41-57.</li>
<li>Facure, M. (2023). Causal Inference in Python. &quot; O&rsquo;Reilly Media, Inc.&quot;.</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://amohammadzadeh.github.io/tags/casual-inference/">Casual Inference</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://amohammadzadeh.github.io/posts/learning-ab-testing/">
    <span class="title">« Prev</span>
    <br>
    <span>Exploring the Foundations of A/B Testing</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Be Careful What You Control For on x"
            href="https://x.com/intent/tweet/?text=Be%20Careful%20What%20You%20Control%20For&amp;url=https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f&amp;hashtags=CasualInference">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Be Careful What You Control For on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f&amp;title=Be%20Careful%20What%20You%20Control%20For&amp;summary=Be%20Careful%20What%20You%20Control%20For&amp;source=https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Be Careful What You Control For on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f&title=Be%20Careful%20What%20You%20Control%20For">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Be Careful What You Control For on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Be Careful What You Control For on whatsapp"
            href="https://api.whatsapp.com/send?text=Be%20Careful%20What%20You%20Control%20For%20-%20https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Be Careful What You Control For on telegram"
            href="https://telegram.me/share/url?text=Be%20Careful%20What%20You%20Control%20For&amp;url=https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Be Careful What You Control For on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Be%20Careful%20What%20You%20Control%20For&u=https%3a%2f%2famohammadzadeh.github.io%2fposts%2fbe-careful-what-you-control-for%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://amohammadzadeh.github.io/">AMDev</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
